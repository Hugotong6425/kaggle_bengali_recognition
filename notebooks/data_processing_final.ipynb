{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T12:46:05.613172Z",
     "start_time": "2020-03-03T12:46:05.607814Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sys import getsizeof, getrefcount\n",
    "import psutil\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T12:51:37.281874Z",
     "start_time": "2020-03-03T12:51:37.263897Z"
    }
   },
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "SIZE = 224\n",
    "\n",
    "def bbox(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    return rmin, rmax, cmin, cmax\n",
    "\n",
    "def crop_resize(img0, size=SIZE, pad=16):\n",
    "    #crop a box around pixels large than the threshold \n",
    "    #some images contain line at the sides\n",
    "    ymin,ymax,xmin,xmax = bbox(img0[5:-5,5:-5] > 80)\n",
    "    #cropping may cut too much, so we need to add it back\n",
    "    xmin = xmin - 13 if (xmin > 13) else 0\n",
    "    ymin = ymin - 10 if (ymin > 10) else 0\n",
    "    xmax = xmax + 13 if (xmax < WIDTH - 13) else WIDTH\n",
    "    ymax = ymax + 10 if (ymax < HEIGHT - 10) else HEIGHT\n",
    "    img0 = img0[ymin:ymax,xmin:xmax]\n",
    "    #remove lo intensity pixels as noise\n",
    "    img0[img0 < 28] = 0\n",
    "    lx, ly = xmax-xmin,ymax-ymin\n",
    "    l = max(lx,ly) + pad\n",
    "    #make sure that the aspect ratio is kept in rescaling\n",
    "    img0 = np.pad(img0, [((l-ly)//2,), ((l-lx)//2,)], mode='constant')\n",
    "    return cv2.resize(img0,(size,size))\n",
    "\n",
    "def proces_image(images):\n",
    "    \"\"\"\n",
    "    images: (batch_size, 32332), np array\n",
    "    \n",
    "    \"\"\"\n",
    "    processed_image_list = []\n",
    "\n",
    "    for idx in tqdm(range(len(images))):\n",
    "        img0 = 255 - images[idx].reshape(HEIGHT, WIDTH).astype(np.uint8)\n",
    "        #normalize each image by its max val\n",
    "        img = (img0*(255.0/img0.max())).astype(np.uint8)\n",
    "        processed_image_list.append(crop_resize(img))\n",
    "    \n",
    "    return np.array(processed_image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T12:51:37.792424Z",
     "start_time": "2020-03-03T12:51:37.787141Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "PROCESS_DATA = Path(\"../data/processed_data/size_224\")\n",
    "RAW_DATA = Path(\"../data\")\n",
    "\n",
    "PROCESS_DATA.mkdir(exist_ok=True, parents=True)\n",
    "RAW_DATA.mkdir(exist_ok=True,parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-03T12:51:39.153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 0 ==================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 141/50210 [00:00<00:35, 1405.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5118995979428291\n",
      "76.77163314819336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50210/50210 [00:35<00:00, 1432.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97030\n",
      "2.3463155031204224\n",
      "74.90362548828125\n",
      "==================== 1 ==================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 151/50210 [00:00<00:33, 1507.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5118995979428291\n",
      "73.32120895385742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50210/50210 [00:33<00:00, 1476.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32350\n",
      "2.3463155031204224\n",
      "71.30728912353516\n",
      "==================== 2 ==================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 144/50210 [00:00<00:34, 1432.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5118995979428291\n",
      "69.72334671020508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 47519/50210 [00:31<00:01, 1500.06it/s]"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "for i in range(4):\n",
    "    print(f\"==================== {i} ==================\")\n",
    "    fn = f\"train_image_data_{i}.parquet\"\n",
    "    process_fn = f\"train_data_{i}.pickle\"\n",
    "    df = pd.read_parquet(RAW_DATA/fn)\n",
    "    \n",
    "    \n",
    "    if (PROCESS_DATA/process_fn).is_file():\n",
    "        print(f'parquet {i} processed already, skipped')\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    \n",
    "    merged_df = df.merge(train_df, on=\"image_id\")\n",
    "\n",
    "    image_name = merged_df[\"image_id\"]\n",
    "    label = merged_df[[\"grapheme_root\",\"vowel_diacritic\",\"consonant_diacritic\"]].astype(np.uint8)\n",
    "    image = merged_df.drop([\"image_id\", \"grapheme_root\",\"vowel_diacritic\",\"consonant_diacritic\", \"grapheme\"], axis=1).values\n",
    "\n",
    "    \n",
    "    # full image processing\n",
    "    image = image * 1\n",
    "\n",
    "    print(getsizeof(image)/1024/1024/1024)\n",
    "    print(psutil.virtual_memory()[4]/1024/1024/1024)\n",
    "\n",
    "    image = proces_image(image)\n",
    "    print(gc.collect())\n",
    "    print(getsizeof(image)/1024/1024/1024)\n",
    "    print(psutil.virtual_memory()[4]/1024/1024/1024)\n",
    "    \n",
    "    with open(PROCESS_DATA/process_fn, \"wb\") as f:\n",
    "#         pickle.dump(image, f)\n",
    "        pickle.dump((image, image_name, label.values), f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T12:46:13.091902Z",
     "start_time": "2020-03-03T12:46:09.218Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# strange thing in memory\n",
    "print(getsizeof(image)/1024/1024/1024)\n",
    "print(psutil.virtual_memory()[4]/1024/1024/1024)\n",
    "image = image * 1\n",
    "print(getsizeof(image)/1024/1024/1024)\n",
    "print(psutil.virtual_memory()[4]/1024/1024/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T12:46:13.092551Z",
     "start_time": "2020-03-03T12:46:09.400Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(getsizeof(image)/1024/1024/1024)\n",
    "\n",
    "image_max = image.max(axis=1).reshape(-1, 1).astype(np.uint8)\n",
    "print(getsizeof(image_max))\n",
    "\n",
    "image = (255 - image)/image_max*255\n",
    "print(getsizeof(image)/1024/1024/1024)\n",
    "\n",
    "image = image.reshape(-1, HEIGHT, WIDTH).astype(np.uint8)\n",
    "print(getsizeof(image)/1024/1024/1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T12:46:13.093494Z",
     "start_time": "2020-03-03T12:46:09.606Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_image_list = []\n",
    "\n",
    "for idx in tqdm(range(len(image))):\n",
    "    processed_image_list.append(crop_resize(image[idx]))\n",
    "    \n",
    "\n",
    "# result_list = []\n",
    "\n",
    "# for idx in tqdm(range(len(image))):\n",
    "#     root, vowel, consonant = label.values[idx]\n",
    "#     result_list.append({\n",
    "#         \"image\": crop_resize(image[idx]),\n",
    "#         \"name\": image_name[idx],\n",
    "#         \"grapheme_root\": root,\n",
    "#         \"vowel_diacritic\": vowel,\n",
    "#         \"consonant_diacritic\": consonant\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T12:46:13.094247Z",
     "start_time": "2020-03-03T12:46:09.811Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array(processed_image_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T12:46:13.094944Z",
     "start_time": "2020-03-03T12:46:10.007Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# size 224 X 224 \n",
    "for i in range(5):\n",
    "    plt.imshow(processed_image_list[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T04:47:37.731065Z",
     "start_time": "2020-01-15T04:47:36.782621Z"
    }
   },
   "outputs": [],
   "source": [
    "a = (np.array(processed_image_list), image_name, label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T04:47:37.739634Z",
     "start_time": "2020-01-15T04:47:37.732452Z"
    }
   },
   "outputs": [],
   "source": [
    "a[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T04:47:40.222057Z",
     "start_time": "2020-01-15T04:47:37.740966Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"train_data_0.pickle\", \"wb\") as f:\n",
    "    pickle.dump(a, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T09:42:01.480836Z",
     "start_time": "2020-01-03T09:41:55.962994Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../data/processed_data/train_data_0.pickle\", \"rb\") as f:\n",
    "    data_list = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
