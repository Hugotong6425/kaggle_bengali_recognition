{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T05:39:44.778191Z",
     "start_time": "2020-01-21T05:39:44.396941Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import apex\n",
    "from apex import amp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from efficientnet_pytorch.utils import MemoryEfficientSwish\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from useful_optim import Over9000\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T05:39:44.784413Z",
     "start_time": "2020-01-21T05:39:44.779578Z"
    }
   },
   "outputs": [],
   "source": [
    "class GraphemeDataset(Dataset):\n",
    "    def __init__(self, image, label, transforms=None):\n",
    "        self.image = image\n",
    "        self.label = label\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.image.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.image[idx]\n",
    "        if self.transforms is not None:\n",
    "            data = self.transforms(data)\n",
    "        root, vowel, consonant = self.label[idx]\n",
    "        return data, root, vowel, consonant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T05:39:44.872997Z",
     "start_time": "2020-01-21T05:39:44.786647Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(pickle_paths):\n",
    "    # load data from pickle\n",
    "    image_data = []\n",
    "    name_data = []\n",
    "    label_data = []\n",
    "\n",
    "    for pickle_path in pickle_paths:\n",
    "        with open(pickle_path, \"rb\") as f:\n",
    "            train_data = pickle.load(f)\n",
    "            image_data.append(train_data[0])\n",
    "            name_data.append(train_data[1])\n",
    "            label_data.append(train_data[2])\n",
    "\n",
    "    image_data = np.array(image_data)\n",
    "    name_data = np.array(name_data)\n",
    "    label_data = np.array(label_data)\n",
    "\n",
    "    # print(image_data.shape, name_data.shape, label_data.shape)\n",
    "\n",
    "    image_data = image_data.reshape(image_data.shape[0]*image_data.shape[1], 224, 224)\n",
    "    name_data = name_data.reshape(-1)\n",
    "    label_data = label_data.reshape(label_data.shape[0]*label_data.shape[1], 3)\n",
    "\n",
    "    print(f\"Load data done, shape: {image_data.shape}, {name_data.shape}, {label_data.shape}\")\n",
    "    return image_data, name_data, label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T05:39:44.928977Z",
     "start_time": "2020-01-21T05:39:44.875648Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(num_train, valid_size, random_seed):\n",
    "    # random train test split\n",
    "    indices = list(range(num_train))\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    \n",
    "    return train_idx, valid_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T05:39:45.012705Z",
     "start_time": "2020-01-21T05:39:44.999289Z"
    }
   },
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, in_feature, n_class, ps=0.5):\n",
    "        super().__init__()\n",
    "        self._fc = nn.Linear(in_feature, n_class)\n",
    "        self._swish = MemoryEfficientSwish()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self._fc(x)\n",
    "        x = self._swish(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class Grapheme_network(nn.Module):\n",
    "    def __init__(self, head, backbone_out_feature):\n",
    "        super().__init__()\n",
    "        \n",
    "#         eff_b0_backbone = EfficientNet.from_pretrained('efficientnet-b0') \n",
    "#         eff_b0_backbone = nn.Sequential(*list(eff_b0_backbone.children())[:-2])\n",
    "#         self.backbone = eff_b0_backbone\n",
    "        \n",
    "        eff_b0_backbone = EfficientNet.from_pretrained('efficientnet-b0') \n",
    "        self.backbone = nn.Sequential(\n",
    "            eff_b0_backbone._conv_stem,\n",
    "            eff_b0_backbone._bn0,\n",
    "            eff_b0_backbone._blocks,\n",
    "            eff_b0_backbone._conv_head,\n",
    "            eff_b0_backbone._bn1,\n",
    "            eff_b0_backbone._avg_pooling,\n",
    "            eff_b0_backbone._dropout,\n",
    "        )\n",
    "        \n",
    "        self.head_root = head(backbone_out_feature, 168)\n",
    "        self.head_vowel = head(backbone_out_feature, 11)\n",
    "        self.head_consonant = head(backbone_out_feature, 7)\n",
    "        \n",
    "    def forward(self, x):    \n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        x1 = self.head_root(x)\n",
    "        x2 = self.head_vowel(x)\n",
    "        x3 = self.head_consonant(x)\n",
    "        \n",
    "        return x1,x2,x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T05:39:45.141663Z",
     "start_time": "2020-01-21T05:39:45.128557Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_phrase(model, optimizer, train_dataloader, criterion, num_train, mixed_precision):\n",
    "\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for image, root, vowel, consonant in tqdm_notebook(train_dataloader):\n",
    "        image = image.to(\"cuda\")\n",
    "        root = root.long().to(\"cuda\")\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(image)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, root)\n",
    "\n",
    "        # backward + optimize\n",
    "        if mixed_precision:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * image.size(0)\n",
    "        running_corrects += torch.sum(preds == root.data)\n",
    "\n",
    "    train_loss = running_loss / float(num_train)\n",
    "    train_acc = running_corrects.double() / num_train\n",
    "    \n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T05:39:45.294776Z",
     "start_time": "2020-01-21T05:39:45.272046Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate_phrase(model, valid_dataloader, criterion, num_val):\n",
    "    # Each epoch has a training and validation phase\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for image, root, vowel, consonant in tqdm_notebook(valid_dataloader):\n",
    "        image = image.to(\"cuda\")\n",
    "        root = root.long().to(\"cuda\")\n",
    "\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(image)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, root)\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * image.size(0)\n",
    "        running_corrects += torch.sum(preds == root.data)\n",
    "\n",
    "    val_loss = running_loss / float(num_val)\n",
    "    val_acc = running_corrects.double() / num_val\n",
    "\n",
    "    return val_loss, val_acc\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model, criterion, optimizer, dataloaders, \n",
    "    mixed_precision, callbacks, num_epochs=25, scheduler=None\n",
    "):\n",
    "    callbacks[\"train_loss_list\"] = []\n",
    "    callbacks[\"train_acc_list\"] = []\n",
    "    callbacks[\"val_loss_list\"] = []\n",
    "    callbacks[\"val_acc_list\"] = []\n",
    "    \n",
    "    since = time.time()\n",
    "    \n",
    "    num_train = len(dataloaders[\"train\"].dataset)\n",
    "    num_val = len(dataloaders[\"val\"].dataset)\n",
    "    \n",
    "    #high_acc_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    #low_loss_model_wts = copy.deepcopy(model.state_dict())\n",
    "    lowest_loss = 999\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        train_loss, train_acc = train_phrase(\n",
    "            model, optimizer, dataloaders[\"train\"], criterion, num_train, mixed_precision\n",
    "        )\n",
    "        print(\"Train Loss: {:.4f} Acc: {:.4f}\".format(train_loss, train_acc))\n",
    "        \n",
    "        val_loss, val_acc = validate_phrase(\n",
    "            model, dataloaders[\"val\"], criterion, num_val\n",
    "        )\n",
    "        print(\"Val Loss: {:.4f} Acc: {:.4f}\".format(val_loss, val_acc))\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "        \n",
    "        # deep copy the model\n",
    "        if val_acc > best_acc:\n",
    "            print(f\"In epoch {epoch}, highest val accuracy increases from {best_acc} to {val_acc}.\")\n",
    "            best_acc = val_acc\n",
    "            # high_acc_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), \"./eff_0_high_acc.pth\")\n",
    "\n",
    "        # deep copy the model\n",
    "        if val_loss < lowest_loss:\n",
    "            print(f\"In epoch {epoch}, lowest val loss decreases from {lowest_loss} to {val_loss}.\")\n",
    "            lowest_loss = val_loss\n",
    "            # low_loss_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), \"./eff_0_low_loss.pth\")\n",
    "        \n",
    "        callbacks[\"train_loss_list\"].append(train_loss)\n",
    "        callbacks[\"train_acc_list\"].append(train_acc)\n",
    "        callbacks[\"val_loss_list\"].append(val_loss)\n",
    "        callbacks[\"val_acc_list\"].append(val_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    return callbacks\n",
    "\n",
    "    ## load best model weights\n",
    "    #model.load_state_dict(best_model_wts)\n",
    "    # return best_model_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T05:39:45.421005Z",
     "start_time": "2020-01-21T05:39:45.414801Z"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "#     mean = np.array([0.485, 0.456, 0.406])\n",
    "#     std = np.array([0.229, 0.224, 0.225])\n",
    "#     inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T05:39:48.159196Z",
     "start_time": "2020-01-21T05:39:45.552834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data done, shape: (50210, 224, 224), (50210,), (50210, 3)\n"
     ]
    }
   ],
   "source": [
    "# load data \n",
    "pickle_paths = [\n",
    "    \"../data/processed_data/size_224/train_data_0.pickle\",\n",
    "#     \"../data/processed_data/size_224/train_data_1.pickle\",\n",
    "#     \"../data/processed_data/size_224/train_data_2.pickle\",\n",
    "#     \"../data/processed_data/size_224/train_data_3.pickle\",\n",
    "]\n",
    "\n",
    "image_data, name_data, label_data = load_data(pickle_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T05:39:49.092451Z",
     "start_time": "2020-01-21T05:39:48.161450Z"
    }
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomAffine(degrees=10, scale=(1.0, 1.15)),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.0692], [0.2051]),\n",
    "        # transforms.ToPILImage(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.0692], [0.2051])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "valid_size = 0.2\n",
    "random_seed = 2020\n",
    "num_train = len(label_data)\n",
    "\n",
    "train_idx, valid_idx = train_test_split(\n",
    "    num_train, valid_size, random_seed\n",
    ")\n",
    "\n",
    "train_dataset = GraphemeDataset(\n",
    "    image_data[train_idx], label_data[train_idx], transforms=data_transforms[\"train\"]\n",
    ")\n",
    "val_dataset = GraphemeDataset(\n",
    "    image_data[valid_idx], label_data[valid_idx], transforms=data_transforms[\"val\"]\n",
    ")\n",
    "\n",
    "dataset_sizes = {\n",
    "    \"train\": len(train_dataset),\n",
    "    \"val\": len(val_dataset),\n",
    "}\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 2\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size,\n",
    "    num_workers=num_workers, pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size,\n",
    "    num_workers=num_workers, pin_memory=True,\n",
    ")\n",
    "\n",
    "data_loaders = {\n",
    "    \"train\": train_loader,\n",
    "    \"val\": val_loader,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T05:39:49.097606Z",
     "start_time": "2020-01-21T05:39:49.094547Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get a batch of training data for demo\n",
    "\n",
    "# visual_loader = DataLoader(\n",
    "#     train_dataset, batch_size=4,\n",
    "#     num_workers=num_workers, pin_memory=True,\n",
    "# )\n",
    "\n",
    "# inputs, a,b,c = next(iter(visual_loader))\n",
    "\n",
    "# # Make a grid from batch\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "# imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T05:39:50.966940Z",
     "start_time": "2020-01-21T05:39:49.099705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "eff_b0 = EfficientNet.from_pretrained('efficientnet-b0', num_classes=168)\n",
    "eff_b0.to(\"cuda\")\n",
    "eff_b0 = nn.DataParallel(eff_b0)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# my_list = ['module._fc.weight', 'module._fc.bias']\n",
    "# params = list(filter(lambda kv: kv[0] in my_list, eff_b0.named_parameters()))\n",
    "# base_params = list(filter(lambda kv: kv[0] not in my_list, eff_b0.named_parameters()))\n",
    "\n",
    "# params = [kv[1] for kv in params]\n",
    "# base_params = [kv[1] for kv in base_params]\n",
    "\n",
    "optimizer_ft = optim.Adam(eff_b0.parameters())\n",
    "# optimizer_ft = Over9000(eff_b0.parameters())\n",
    "\n",
    "\n",
    "# mixed_precision = False\n",
    "# if mixed_precision:\n",
    "#     #eff_b0 = apex.parallel.DistributedDataParallel(eff_b0)\n",
    "#     eff_b0.to(\"cuda\")\n",
    "# #     eff_b0 = torch.nn.parallel.DistributedDataParallel(\n",
    "# #         eff_b0, device_ids=[0,1], output_device=0\n",
    "# #     )\n",
    "# #     #\n",
    "#     # eff_b0, optimizer_ft = amp.initialize(eff_b0, optimizer_ft, opt_level=\"O1\")\n",
    "    \n",
    "# else:\n",
    "#     eff_b0 = nn.DataParallel(eff_b0)\n",
    "#     # eff_b0.to(\"cuda\")\n",
    "    \n",
    "    \n",
    "\n",
    "# exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "#     optimizer_ft, factor=0.5, patience=5,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T05:39:51.995580Z",
     "start_time": "2020-01-21T05:39:50.968562Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/anaconda3/envs/kaggle/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d2c0df4bb54620ab83b80ad0a72509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=314.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 28.00 MiB (GPU 0; 10.91 GiB total capacity; 10.27 GiB already allocated; 11.44 MiB free; 96.11 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4835550f2ef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m callbacks = train_model(\n\u001b[1;32m      4\u001b[0m     \u001b[0meff_b0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-7-e749cad61455>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, dataloaders, mixed_precision, callbacks, num_epochs, scheduler)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         train_loss, train_acc = train_phrase(\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixed_precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         )\n\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train Loss: {:.4f} Acc: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-7670e240c20e>\u001b[0m in \u001b[0;36mtrain_phrase\u001b[0;34m(model, optimizer, train_dataloader, criterion, num_train, mixed_precision)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Convolution layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m# Pooling and final linear layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mdrop_connect_rate\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_ratio\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bn0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expand_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depthwise_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1695\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1696\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1697\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1698\u001b[0m     )\n\u001b[1;32m   1699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 28.00 MiB (GPU 0; 10.91 GiB total capacity; 10.27 GiB already allocated; 11.44 MiB free; 96.11 MiB cached)"
     ]
    }
   ],
   "source": [
    "callbacks = {}\n",
    "\n",
    "callbacks = train_model(\n",
    "    eff_b0, criterion, optimizer_ft, data_loaders,\n",
    "    False, callbacks, num_epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T02:05:31.020297Z",
     "start_time": "2020-01-20T02:05:30.839340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss_list': [0.677507182491583,\n",
       "  0.3023412701226971,\n",
       "  0.24030818127346476,\n",
       "  0.19745124878428225,\n",
       "  0.1697998459320504,\n",
       "  0.14861136590299603,\n",
       "  0.13169324549545308,\n",
       "  0.11525725520475051,\n",
       "  0.10444912001167106,\n",
       "  0.09548021738859458,\n",
       "  0.0842854853922023,\n",
       "  0.0811684035169867,\n",
       "  0.07277584672597413,\n",
       "  0.06837365379658289,\n",
       "  0.06252743477390192,\n",
       "  0.03229776572519934,\n",
       "  0.022375330699912297,\n",
       "  0.02074023933286948,\n",
       "  0.019448578888926937,\n",
       "  0.017658451988660964,\n",
       "  0.0181798873577928,\n",
       "  0.009454024783870751,\n",
       "  0.007237659557671501,\n",
       "  0.0057035021808868715,\n",
       "  0.005755487063762748,\n",
       "  0.005590792551704954,\n",
       "  0.005290630607580288,\n",
       "  0.0035891412877717167,\n",
       "  0.002637266023561219,\n",
       "  0.0026325552518969395,\n",
       "  0.002227559764352934,\n",
       "  0.0018614081465920184,\n",
       "  0.0020231755368383345,\n",
       "  0.0013102657493486557,\n",
       "  0.0013122913731661624,\n",
       "  0.0010264889355485502,\n",
       "  0.0009780991032313027,\n",
       "  0.0010433074734619808,\n",
       "  0.0008791102012228001,\n",
       "  0.000815280243306254,\n",
       "  0.0007723400143365228,\n",
       "  0.0007703424960202701,\n",
       "  0.0006967682797247327,\n",
       "  0.0005905768921047158,\n",
       "  0.0006222027964004125,\n",
       "  0.0005463948534544519,\n",
       "  0.0005167466939813325,\n",
       "  0.0004383571055680484,\n",
       "  0.0004216408309910882,\n",
       "  0.0005001183721654041,\n",
       "  0.0004199476616953835,\n",
       "  0.0004386360223040213,\n",
       "  0.0003983275399125446,\n",
       "  0.0003724563136040939,\n",
       "  0.00033268683271516343,\n",
       "  0.0003787697461841591,\n",
       "  0.0003905231212862125,\n",
       "  0.0003984517113095473,\n",
       "  0.00031088700592577206,\n",
       "  0.00031651778146995536,\n",
       "  0.000345066068087458,\n",
       "  0.00036822554718994615,\n",
       "  0.00033636704559132435,\n",
       "  0.0004587213274516615,\n",
       "  0.00033021569133303457,\n",
       "  0.00041512889333857267,\n",
       "  0.00034882663178790546,\n",
       "  0.00039810696058457555,\n",
       "  0.00037105146441604957,\n",
       "  0.00031355112713899445,\n",
       "  0.0003210731170473524,\n",
       "  0.0003774051072795276,\n",
       "  0.0003351360482301543,\n",
       "  0.0003600784077916908,\n",
       "  0.0003309063405671031,\n",
       "  0.00030512229261782224,\n",
       "  0.00034830578115209123,\n",
       "  0.0003176240201871059,\n",
       "  0.0003189906704962384,\n",
       "  0.0003529872557564196,\n",
       "  0.0003675930506203474,\n",
       "  0.00023468012378596138,\n",
       "  0.0003732144417123618,\n",
       "  0.00034353219223459317,\n",
       "  0.000305309603827286,\n",
       "  0.0003188334878781145,\n",
       "  0.0003330407746164382,\n",
       "  0.0004401036575837241,\n",
       "  0.000276747560493976,\n",
       "  0.0004272247020810326,\n",
       "  0.00025999277913221395,\n",
       "  0.0003137137682237038,\n",
       "  0.00028529615130136747,\n",
       "  0.00032914123184247406,\n",
       "  0.00026754225761713293,\n",
       "  0.0002904008726001949,\n",
       "  0.0005215055390293202,\n",
       "  0.00028411839123955527,\n",
       "  0.00032995711567629333,\n",
       "  0.0003396340569244203],\n",
       " 'train_acc_list': [tensor(0.8174, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9109, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9279, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9396, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9478, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9531, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9576, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9634, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9660, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9692, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9719, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9728, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9755, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9771, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9787, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9892, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9924, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9930, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9935, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9940, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9939, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9969, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9978, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9983, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9983, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9982, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9983, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9989, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9992, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9993, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9995, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9995, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9994, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9997, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9997, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9998, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9998, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9998, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9998, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9998, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9998, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9998, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9998, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9998, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9998, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(1.0000, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(1.0000, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(1.0000, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(1.0000, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(1.0000, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9999, device='cuda:0', dtype=torch.float64)],\n",
       " 'val_loss_list': [0.3391013973691363,\n",
       "  0.317141097502698,\n",
       "  0.2963465546598902,\n",
       "  0.2953239898595219,\n",
       "  0.2470434255166444,\n",
       "  0.278353881109428,\n",
       "  0.24243294165277357,\n",
       "  0.2739916849459246,\n",
       "  0.23114501008995025,\n",
       "  0.24803469897954736,\n",
       "  0.30921959828936324,\n",
       "  0.2607537120954612,\n",
       "  0.26948237487980625,\n",
       "  0.2686550165820563,\n",
       "  0.2746992618753672,\n",
       "  0.23378390910686714,\n",
       "  0.24055116516948816,\n",
       "  0.2643481223285495,\n",
       "  0.26680743205217317,\n",
       "  0.2664227842501116,\n",
       "  0.2657672305359733,\n",
       "  0.25274319917978555,\n",
       "  0.26222325574470884,\n",
       "  0.26495121163311436,\n",
       "  0.26976845707107033,\n",
       "  0.27688381252144467,\n",
       "  0.2854838789138536,\n",
       "  0.2712942233980236,\n",
       "  0.27494305833429245,\n",
       "  0.2813390271938125,\n",
       "  0.27773878964810844,\n",
       "  0.2906002950036794,\n",
       "  0.29123245683876886,\n",
       "  0.2823400390893666,\n",
       "  0.28307064662557085,\n",
       "  0.284191078961406,\n",
       "  0.2855067920623085,\n",
       "  0.2878407555565704,\n",
       "  0.2880644237608151,\n",
       "  0.2886642836890499,\n",
       "  0.2893939399785716,\n",
       "  0.2904351515982213,\n",
       "  0.28833720849534233,\n",
       "  0.289870016984649,\n",
       "  0.290010566784789,\n",
       "  0.2911129435311036,\n",
       "  0.29006494633635305,\n",
       "  0.2922692419143104,\n",
       "  0.292871913422486,\n",
       "  0.2932886485914813,\n",
       "  0.2926406715405792,\n",
       "  0.29322187415253853,\n",
       "  0.29474722810818177,\n",
       "  0.29447030691102405,\n",
       "  0.29434399770636216,\n",
       "  0.2941342459461457,\n",
       "  0.29484869984606066,\n",
       "  0.29491721626962475,\n",
       "  0.2953355233108017,\n",
       "  0.2947559253945338,\n",
       "  0.2950418948224996,\n",
       "  0.29494254966818273,\n",
       "  0.295207621483327,\n",
       "  0.29502958575108923,\n",
       "  0.2951249909089918,\n",
       "  0.29559233687926373,\n",
       "  0.29540554889761766,\n",
       "  0.29581304903264016,\n",
       "  0.29617609044181187,\n",
       "  0.2960899516634437,\n",
       "  0.29574985646365815,\n",
       "  0.29641568219725817,\n",
       "  0.2959294840648957,\n",
       "  0.2960046958315541,\n",
       "  0.2963151768416766,\n",
       "  0.2959849229373677,\n",
       "  0.29633738743050403,\n",
       "  0.29649200417610355,\n",
       "  0.2962347793878253,\n",
       "  0.296048027767268,\n",
       "  0.2960859239635608,\n",
       "  0.29618618880531933,\n",
       "  0.2961173329106889,\n",
       "  0.2961201147357916,\n",
       "  0.29631438748671746,\n",
       "  0.29589961895641637,\n",
       "  0.29604712122110133,\n",
       "  0.29596303667212076,\n",
       "  0.29603400820518627,\n",
       "  0.29580292175714057,\n",
       "  0.2962316406352471,\n",
       "  0.29574543358177524,\n",
       "  0.2959065978875129,\n",
       "  0.29593265500588145,\n",
       "  0.2961833905031709,\n",
       "  0.2960252802855369,\n",
       "  0.2960230540562094,\n",
       "  0.2961119095646654,\n",
       "  0.29624646031341334,\n",
       "  0.29618794034021684],\n",
       " 'val_acc_list': [tensor(0.9043, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9077, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9168, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9184, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9334, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9304, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9360, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9308, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9395, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9416, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9291, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9394, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9372, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9391, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9427, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9516, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9529, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9502, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9505, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9520, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9528, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9565, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9565, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9571, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9573, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9567, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9565, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9589, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9588, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9583, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9583, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9578, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9578, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9590, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9591, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9596, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9604, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9598, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9601, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9600, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9603, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9603, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9602, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9605, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9608, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9607, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9609, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9605, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9604, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9607, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9611, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9609, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9605, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9606, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9608, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9606, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9609, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9609, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9608, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9608, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9607, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9607, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9609, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9608, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9607, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9605, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9607, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9609, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9610, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9608, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9608, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9609, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9609, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9609, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9610, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9609, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9610, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9610, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9610, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9609, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9610, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9610, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9610, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9611, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9609, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9610, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9611, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9611, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9610, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9610, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9610, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9611, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9610, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9610, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9611, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9611, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9610, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9610, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9611, device='cuda:0', dtype=torch.float64),\n",
       "  tensor(0.9611, device='cuda:0', dtype=torch.float64)]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T02:05:39.446824Z",
     "start_time": "2020-01-20T02:05:39.441585Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T02:11:07.774881Z",
     "start_time": "2020-01-20T02:11:07.658602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2bc3198a90>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(callbacks[\"train_loss_list\"][1:])\n",
    "plt.plot(callbacks[\"val_loss_list\"][1:])\n",
    "# plt.plot(callbacks[\"train_loss_list\"])\n",
    "# plt.plot(callbacks[\"train_loss_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T02:05:39.632290Z",
     "start_time": "2020-01-20T02:05:39.590944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss_list</th>\n",
       "      <th>train_acc_list</th>\n",
       "      <th>val_loss_list</th>\n",
       "      <th>val_acc_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.677507</td>\n",
       "      <td>tensor(0.8174, device='cuda:0', dtype=torch.fl...</td>\n",
       "      <td>0.339101</td>\n",
       "      <td>tensor(0.9043, device='cuda:0', dtype=torch.fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.302341</td>\n",
       "      <td>tensor(0.9109, device='cuda:0', dtype=torch.fl...</td>\n",
       "      <td>0.317141</td>\n",
       "      <td>tensor(0.9077, device='cuda:0', dtype=torch.fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.240308</td>\n",
       "      <td>tensor(0.9279, device='cuda:0', dtype=torch.fl...</td>\n",
       "      <td>0.296347</td>\n",
       "      <td>tensor(0.9168, device='cuda:0', dtype=torch.fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.197451</td>\n",
       "      <td>tensor(0.9396, device='cuda:0', dtype=torch.fl...</td>\n",
       "      <td>0.295324</td>\n",
       "      <td>tensor(0.9184, device='cuda:0', dtype=torch.fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.169800</td>\n",
       "      <td>tensor(0.9478, device='cuda:0', dtype=torch.fl...</td>\n",
       "      <td>0.247043</td>\n",
       "      <td>tensor(0.9334, device='cuda:0', dtype=torch.fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000290</td>\n",
       "      <td>tensor(0.9999, device='cuda:0', dtype=torch.fl...</td>\n",
       "      <td>0.296025</td>\n",
       "      <td>tensor(0.9611, device='cuda:0', dtype=torch.fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000522</td>\n",
       "      <td>tensor(0.9999, device='cuda:0', dtype=torch.fl...</td>\n",
       "      <td>0.296023</td>\n",
       "      <td>tensor(0.9610, device='cuda:0', dtype=torch.fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000284</td>\n",
       "      <td>tensor(1.0000, device='cuda:0', dtype=torch.fl...</td>\n",
       "      <td>0.296112</td>\n",
       "      <td>tensor(0.9610, device='cuda:0', dtype=torch.fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000330</td>\n",
       "      <td>tensor(0.9999, device='cuda:0', dtype=torch.fl...</td>\n",
       "      <td>0.296246</td>\n",
       "      <td>tensor(0.9611, device='cuda:0', dtype=torch.fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000340</td>\n",
       "      <td>tensor(0.9999, device='cuda:0', dtype=torch.fl...</td>\n",
       "      <td>0.296188</td>\n",
       "      <td>tensor(0.9611, device='cuda:0', dtype=torch.fl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss_list                                     train_acc_list  \\\n",
       "0          0.677507  tensor(0.8174, device='cuda:0', dtype=torch.fl...   \n",
       "1          0.302341  tensor(0.9109, device='cuda:0', dtype=torch.fl...   \n",
       "2          0.240308  tensor(0.9279, device='cuda:0', dtype=torch.fl...   \n",
       "3          0.197451  tensor(0.9396, device='cuda:0', dtype=torch.fl...   \n",
       "4          0.169800  tensor(0.9478, device='cuda:0', dtype=torch.fl...   \n",
       "..              ...                                                ...   \n",
       "95         0.000290  tensor(0.9999, device='cuda:0', dtype=torch.fl...   \n",
       "96         0.000522  tensor(0.9999, device='cuda:0', dtype=torch.fl...   \n",
       "97         0.000284  tensor(1.0000, device='cuda:0', dtype=torch.fl...   \n",
       "98         0.000330  tensor(0.9999, device='cuda:0', dtype=torch.fl...   \n",
       "99         0.000340  tensor(0.9999, device='cuda:0', dtype=torch.fl...   \n",
       "\n",
       "    val_loss_list                                       val_acc_list  \n",
       "0        0.339101  tensor(0.9043, device='cuda:0', dtype=torch.fl...  \n",
       "1        0.317141  tensor(0.9077, device='cuda:0', dtype=torch.fl...  \n",
       "2        0.296347  tensor(0.9168, device='cuda:0', dtype=torch.fl...  \n",
       "3        0.295324  tensor(0.9184, device='cuda:0', dtype=torch.fl...  \n",
       "4        0.247043  tensor(0.9334, device='cuda:0', dtype=torch.fl...  \n",
       "..            ...                                                ...  \n",
       "95       0.296025  tensor(0.9611, device='cuda:0', dtype=torch.fl...  \n",
       "96       0.296023  tensor(0.9610, device='cuda:0', dtype=torch.fl...  \n",
       "97       0.296112  tensor(0.9610, device='cuda:0', dtype=torch.fl...  \n",
       "98       0.296246  tensor(0.9611, device='cuda:0', dtype=torch.fl...  \n",
       "99       0.296188  tensor(0.9611, device='cuda:0', dtype=torch.fl...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T10:17:44.580856Z",
     "start_time": "2020-01-17T10:17:44.572674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.62270962)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks[\"train_acc_list\"][0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T07:39:15.958611Z",
     "start_time": "2020-01-15T07:39:15.853380Z"
    }
   },
   "outputs": [],
   "source": [
    "eff_b0_backbone = EfficientNet.from_pretrained('efficientnet-b0') \n",
    "eff_b0_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T07:35:35.994862Z",
     "start_time": "2020-01-15T07:35:35.893510Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# modelling\n",
    "eff_b0_backbone = EfficientNet.from_pretrained('efficientnet-b0') \n",
    "eff_b0_backbone = nn.Sequential(*list(eff_b0_backbone.children())[:-2])\n",
    "eff_b0_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T07:36:23.068684Z",
     "start_time": "2020-01-15T07:36:23.032034Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eff_b0_backbone(torch.ones(1,3, 64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T07:42:04.012921Z",
     "start_time": "2020-01-15T07:42:03.887986Z"
    }
   },
   "outputs": [],
   "source": [
    "eff_b0_backbone = EfficientNet.from_pretrained('efficientnet-b0') \n",
    "backbone = nn.Sequential(\n",
    "    eff_b0_backbone._conv_stem,\n",
    "    eff_b0_backbone._bn0,\n",
    "    eff_b0_backbone._blocks,\n",
    "    eff_b0_backbone._conv_head,\n",
    "    eff_b0_backbone._bn1,\n",
    "    eff_b0_backbone._avg_pooling,\n",
    "    eff_b0_backbone._dropout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T07:42:15.025215Z",
     "start_time": "2020-01-15T07:42:15.000606Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "backbone(torch.ones(1,3, 64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T07:25:41.212540Z",
     "start_time": "2020-01-15T07:25:41.097813Z"
    }
   },
   "outputs": [],
   "source": [
    "backbone_out_feature = 1280\n",
    "\n",
    "eff_b0 = Grapheme_network(Head, backbone_out_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T07:25:43.597852Z",
     "start_time": "2020-01-15T07:25:43.585594Z"
    }
   },
   "outputs": [],
   "source": [
    "eff_b0.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T07:25:57.220286Z",
     "start_time": "2020-01-15T07:25:56.515380Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = next(iter(data_loaders[\"train\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T07:25:57.376086Z",
     "start_time": "2020-01-15T07:25:57.223000Z"
    }
   },
   "outputs": [],
   "source": [
    "eff_b0(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T07:24:47.713174Z",
     "start_time": "2020-01-15T07:24:47.701955Z"
    }
   },
   "outputs": [],
   "source": [
    "eff_b0_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T07:24:46.490899Z",
     "start_time": "2020-01-15T07:24:45.396695Z"
    }
   },
   "outputs": [],
   "source": [
    "eff_b0_backbone(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T07:14:40.592412Z",
     "start_time": "2020-01-15T07:14:40.365396Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "eff_b0(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T07:18:15.804052Z",
     "start_time": "2020-01-15T07:18:14.488577Z"
    }
   },
   "outputs": [],
   "source": [
    "eff_b0_backbone(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
