{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T05:22:38.382756Z",
     "start_time": "2020-01-05T05:22:38.084130Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "\n",
    "from hw_grapheme.dl_utils.radam import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T05:22:38.397121Z",
     "start_time": "2020-01-05T05:22:38.385188Z"
    }
   },
   "outputs": [],
   "source": [
    "sz = 128\n",
    "bs = 64\n",
    "nfolds = 4 #keep the same split as the initial dataset\n",
    "fold = 0\n",
    "SEED = 2019\n",
    "TRAIN = '../input/grapheme-imgs-128x128/'\n",
    "LABELS = '../input/bengaliai-cv19/train.csv'\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T05:22:38.478476Z",
     "start_time": "2020-01-05T05:22:38.403260Z"
    }
   },
   "outputs": [],
   "source": [
    "class Loss_combine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, input, target,reduction='mean'):\n",
    "        x1,x2,x3 = input\n",
    "        x1,x2,x3 = x1.float(),x2.float(),x3.float()\n",
    "        y = target.long()\n",
    "        return 0.7*F.cross_entropy(x1,y[:,0],reduction=reduction) + 0.1*F.cross_entropy(x2,y[:,1],reduction=reduction) + \\\n",
    "          0.2*F.cross_entropy(x3,y[:,2],reduction=reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T05:22:38.560566Z",
     "start_time": "2020-01-05T05:22:38.481113Z"
    }
   },
   "outputs": [],
   "source": [
    "class GraphemeDataset(Dataset):\n",
    "    def __init__(self, data_list, _type='train'):            \n",
    "        self.data_list = data_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data_list[idx]\n",
    "        # name = data[\"name\"]\n",
    "        image = data[\"image\"]\n",
    "        grapheme_root = data[\"grapheme_root\"]\n",
    "        vowel_diacritic = data[\"vowel_diacritic\"]\n",
    "        consonant_diacritic = data[\"consonant_diacritic\"]\n",
    "        return image, vowel_diacritic, grapheme_root, consonant_diacritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T05:22:38.688773Z",
     "start_time": "2020-01-05T05:22:38.581085Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50,self).__init__()\n",
    "        \n",
    "        arch = models.resnet50(num_classes=1000, pretrained=True)\n",
    "        arch = list(arch.children())\n",
    "        w = arch[0].weight\n",
    "        arch[0] = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=2, bias=False)\n",
    "        arch[0].weight = nn.Parameter(torch.mean(w, dim=1, keepdim=True))\n",
    "        self.backbone = nn.Sequential(*arch[:-1])\n",
    "        \n",
    "        # vowel_diacritic\n",
    "        self.fc1 = nn.Linear(2048,11)\n",
    "        # grapheme_root\n",
    "        self.fc2 = nn.Linear(2048,168)\n",
    "        # consonant_diacritic\n",
    "        self.fc3 = nn.Linear(2048,7)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = x.view(-1, 2048)\n",
    "        # print(\"x: \", x.shape)\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.fc2(x)\n",
    "        x3 = self.fc3(x)\n",
    "        \n",
    "        return x1,x2,x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T05:22:39.797939Z",
     "start_time": "2020-01-05T05:22:38.698183Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "with open(\"../data/processed_data/train_data_0.pickle\", \"rb\") as f:\n",
    "    data_list = pickle.load(f)\n",
    "    \n",
    "train_dataset = GraphemeDataset(data_list)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T05:22:41.074882Z",
     "start_time": "2020-01-05T05:22:41.054085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50210"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T05:22:41.216240Z",
     "start_time": "2020-01-05T05:22:41.192564Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8),\n",
       " tensor([7, 2, 2, 7, 1, 0, 1, 0, 9, 2, 1, 4, 1, 0, 2, 1, 9, 7, 7, 0, 4, 5, 1, 7,\n",
       "         0, 9, 7, 1, 1, 0, 0, 4], dtype=torch.uint8),\n",
       " tensor([149,  72, 140, 147,  75,  21, 107,   6,  15,  68, 123,  28, 159,  89,\n",
       "          64,  92, 103, 107,  53,  72, 148, 113,  97, 112,  71, 150,  26, 123,\n",
       "          67,  94,  48,  64], dtype=torch.uint8),\n",
       " tensor([0, 2, 5, 4, 0, 0, 0, 1, 5, 0, 1, 0, 5, 4, 5, 0, 5, 0, 2, 2, 0, 5, 0, 0,\n",
       "         4, 0, 0, 4, 0, 0, 0, 0], dtype=torch.uint8)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T05:22:44.175098Z",
     "start_time": "2020-01-05T05:22:41.363077Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ResNet50()\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T05:22:44.186685Z",
     "start_time": "2020-01-05T05:22:44.179621Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = RAdam(model.parameters(), lr=1e-3)\n",
    "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-4, max_lr=0.05)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T05:22:44.372857Z",
     "start_time": "2020-01-05T05:22:44.188864Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs, vowel, root, consonant = iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T05:22:44.491823Z",
     "start_time": "2020-01-05T05:22:44.375737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-05T05:22:42.567Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1570/1570 [03:30<00:00,  7.47it/s]\n",
      "  0%|          | 0/1570 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running_acc_vowel : 0.87%\n",
      "running_acc_root : 0.52%\n",
      "running_acc_consonant : 0.89%\n",
      "loss : 2.6932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1570/1570 [03:19<00:00,  7.86it/s]\n",
      "  0%|          | 1/1570 [00:00<03:46,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running_acc_vowel : 0.94%\n",
      "running_acc_root : 0.78%\n",
      "running_acc_consonant : 0.94%\n",
      "loss : 1.1938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1570/1570 [03:17<00:00,  7.97it/s]\n",
      "  0%|          | 1/1570 [00:00<03:40,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running_acc_vowel : 0.96%\n",
      "running_acc_root : 0.84%\n",
      "running_acc_consonant : 0.96%\n",
      "loss : 0.8610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 346/1570 [00:42<02:26,  8.36it/s]"
     ]
    }
   ],
   "source": [
    "epochs = 50 # original 50\n",
    "model.train()\n",
    "losses = []\n",
    "accs = []\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    running_acc_vowel = 0.0\n",
    "    running_acc_root = 0.0\n",
    "    running_acc_consonant = 0.0\n",
    "    \n",
    "    for idx, (inputs, vowel, root, consonant) in tqdm(enumerate(train_loader),total=len(train_loader)):\n",
    "        inputs = inputs.to(device)\n",
    "        vowel = vowel.to(device)\n",
    "        root = root.to(device)\n",
    "        consonant = consonant.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs1, outputs2, outputs3 = model(inputs.unsqueeze(1).float())\n",
    "        # print(\"outputs1: \", outputs1)\n",
    "#         print(\"inputs: \", inputs.shape)\n",
    "#         print(\"outputs1.shape: \", outputs1.shape)\n",
    "#         print(\"vowel: \", vowel.shape)\n",
    "        loss1 = criterion(outputs1, vowel.long())\n",
    "        loss2 = criterion(outputs2, root.long())\n",
    "        loss3 = criterion(outputs3, consonant.long())\n",
    "        \n",
    "        mini_batch_loss = loss1 + loss2 + loss3\n",
    "        running_loss += mini_batch_loss * inputs.size(0)\n",
    "        running_acc_vowel += (outputs1.argmax(1) == vowel.long()).sum()\n",
    "        running_acc_root += (outputs2.argmax(1) == root.long()).sum()\n",
    "        running_acc_consonant += (outputs3.argmax(1) == consonant.long()).sum()\n",
    "        \n",
    "        mini_batch_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    #scheduler.step()\n",
    "    losses.append(running_loss/len(train_dataset))\n",
    "    print('running_acc_vowel : {:.2f}%'.format(running_acc_vowel.float()/len(train_dataset)))\n",
    "    print('running_acc_root : {:.2f}%'.format(running_acc_root.float()/len(train_dataset)))\n",
    "    print('running_acc_consonant : {:.2f}%'.format(running_acc_consonant.float()/len(train_dataset)))\n",
    "\n",
    "    print('loss : {:.4f}'.format(running_loss/len(train_loader)))\n",
    "    \n",
    "torch.save(model.state_dict(), 'resnet34_50epochs_saved_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T05:22:07.173624Z",
     "start_time": "2020-01-05T05:22:07.164079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 2.6936\n"
     ]
    }
   ],
   "source": [
    "print('loss : {:.4f}'.format(running_loss/len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T05:21:44.425563Z",
     "start_time": "2020-01-05T05:21:44.407702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8655, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_acc_vowel.float()/len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T05:22:23.825845Z",
     "start_time": "2020-01-05T05:22:23.814739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running_acc_vowel : 0.87%\n",
      "running_acc_root : 0.52%\n",
      "running_acc_consonant : 0.89%\n"
     ]
    }
   ],
   "source": [
    "    print('running_acc_vowel : {:.2f}%'.format(running_acc_vowel.float()/len(train_dataset)))\n",
    "    print('running_acc_root : {:.2f}%'.format(running_acc_root.float()/len(train_dataset)))\n",
    "    print('running_acc_consonant : {:.2f}%'.format(running_acc_consonant.float()/len(train_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T05:12:04.348664Z",
     "start_time": "2020-01-05T05:12:04.333877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 11])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T05:14:06.299046Z",
     "start_time": "2020-01-05T05:14:06.277935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4, device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(outputs1.argmax(1) == vowel.long()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-05T05:12:27.099937Z",
     "start_time": "2020-01-05T05:12:27.083350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 1, 1, 0, 0, 5, 1, 2, 1, 1, 3, 9, 4, 7, 3, 0, 4, 0, 0, 7, 7, 9, 0, 6,\n",
       "        2, 7, 0, 7, 2, 1, 4, 0], device='cuda:0', dtype=torch.uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
