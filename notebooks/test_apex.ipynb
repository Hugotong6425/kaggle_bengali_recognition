{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment\n",
    "\n",
    "1. People say nn.DistributedDataParallel is way faster than nn.DataParallel (50%)\n",
    "\n",
    "  - https://zhuanlan.zhihu.com/p/95700549\n",
    "\n",
    "  - https://zhuanlan.zhihu.com/p/68717029\n",
    "\n",
    "---\n",
    "\n",
    "2. apex default use nn.DistributedDataParallel (But the below code use nn.DataParallel)\n",
    "\n",
    "  - https://github.com/NVIDIA/apex\n",
    "  - https://github.com/NVIDIA/apex/tree/master/examples/imagenet\n",
    "  \n",
    "**Can try to replace nn.DataParallel by nn.DistributedDataParallel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T07:37:33.960915Z",
     "start_time": "2020-01-24T07:37:33.949424Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T07:37:35.320085Z",
     "start_time": "2020-01-24T07:37:34.502411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use this log_lamb_rs, please run 'pip install tensorboardx'. Also you must have Tensorboard running to see results\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from hw_grapheme.train import generate_stratified_k_fold_index, train_model\n",
    "from hw_grapheme.utils import load_model_weight\n",
    "from hw_grapheme.data_pipeline import create_dataloaders, load_data\n",
    "from hw_grapheme.model import EfficientNet_0\n",
    "from hw_grapheme.loss_func import Loss_combine\n",
    "\n",
    "from torchtools.optim import RangerLars, RAdam\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "from apex import amp\n",
    "from apex.parallel import DistributedDataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_apex(mixed_precision, cuda_parallel, batch_size, opt_level):\n",
    "    # not support in nb\n",
    "    # if mixed_precision and cuda_parallel:\n",
    "    #     torch.cuda.set_device(0)\n",
    "    #     torch.distributed.init_process_group(backend=\"nccl\", init_method='env://')\n",
    "\n",
    "    # load data \n",
    "    pickle_paths = [\n",
    "        \"../data/processed_data/size_224/train_data_0.pickle\",\n",
    "    #     \"../data/processed_data/size_224/train_data_1.pickle\",\n",
    "    #     \"../data/processed_data/size_224/train_data_2.pickle\",\n",
    "    #     \"../data/processed_data/size_224/train_data_3.pickle\",\n",
    "    ]\n",
    "\n",
    "    image_data, name_data, label_data = load_data(pickle_paths)\n",
    "    \n",
    "    batch_size = batch_size\n",
    "    num_workers = 6\n",
    "\n",
    "    pin_memory = True\n",
    "    n_epoch = 120\n",
    "\n",
    "    n_splits = 5\n",
    "    random_seed = 2020\n",
    "\n",
    "    train_idx_list, valid_idx_list = generate_stratified_k_fold_index(\n",
    "        image_data, label_data, n_splits, random_seed\n",
    "    )\n",
    "\n",
    "    train_idx = train_idx_list[0]\n",
    "    valid_idx = valid_idx_list[0]\n",
    "\n",
    "    # create loss function\n",
    "    criterion = Loss_combine()\n",
    "\n",
    "    # create data_transforms\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Grayscale(num_output_channels=3),\n",
    "            transforms.ToTensor(),\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Grayscale(num_output_channels=3),\n",
    "            transforms.ToTensor(),\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    # create model \n",
    "    eff_b0 = EfficientNet_0()\n",
    "\n",
    "    # create optimizer\n",
    "    optimizer_ft = optim.Adam(eff_b0.parameters())\n",
    "\n",
    "    # create data loader\n",
    "    data_loaders = create_dataloaders(\n",
    "        image_data, name_data, label_data, train_idx, valid_idx, \n",
    "        data_transforms, batch_size, num_workers, pin_memory\n",
    "    )\n",
    "    \n",
    "    if mixed_precision and cuda_parallel:\n",
    "        eff_b0.to(\"cuda\")\n",
    "        eff_b0, optimizer_ft = amp.initialize(eff_b0, optimizer_ft, opt_level=opt_level)\n",
    "        eff_b0 = nn.DataParallel(eff_b0)\n",
    "\n",
    "    elif mixed_precision and not cuda_parallel:\n",
    "        eff_b0.to(\"cuda\")\n",
    "        eff_b0, optimizer_ft = amp.initialize(eff_b0, optimizer_ft, opt_level=opt_level)\n",
    "    elif not mixed_precision and cuda_parallel:\n",
    "        eff_b0.to(\"cuda\")\n",
    "        eff_b0 = nn.DataParallel(eff_b0)\n",
    "    elif not mixed_precision and not cuda_parallel:\n",
    "        eff_b0.to(\"cuda\")\n",
    "        \n",
    "    callbacks = {}\n",
    "\n",
    "    callbacks = train_model(\n",
    "        eff_b0, criterion, optimizer_ft, data_loaders,\n",
    "        mixed_precision, callbacks, num_epochs=n_epoch,\n",
    "        epoch_scheduler=None, save_dir=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ 5.2 iterations/s\n",
    "# GPU RAM before start: 1, 1288\n",
    "# GPU RAM after start: 7146, 1299\n",
    "# GPU util before start: 0%, 7%\n",
    "# GPU util after start: 94%, 10%\n",
    "\n",
    "batch_size = 64\n",
    "opt_level = \"O1\"\n",
    "mixed_precision = False\n",
    "cuda_parallel = False\n",
    "\n",
    "test_apex(mixed_precision, cuda_parallel, batch_size, opt_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode: ~6.3 iterations/s\n",
    "# GPU RAM before start: 1, 1288\n",
    "# GPU RAM after start: 4090, 5368\n",
    "# GPU util before start: 0%, 7%\n",
    "# GPU util after start: 61%, 57%\n",
    "\n",
    "batch_size = 64\n",
    "opt_level = \"O1\"\n",
    "mixed_precision = False\n",
    "cuda_parallel = True\n",
    "\n",
    "test_apex(mixed_precision, cuda_parallel, batch_size, opt_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode: ~6.0 iterations/s\n",
    "# GPU RAM before start: 1, 1288\n",
    "# GPU RAM after start: 4532, 1299\n",
    "# GPU util before start: 0%, 7%\n",
    "# GPU util after start: 80%, 10%\n",
    "\n",
    "batch_size = 64\n",
    "opt_level = \"O1\"\n",
    "mixed_precision = True\n",
    "cuda_parallel = False\n",
    "\n",
    "test_apex(mixed_precision, cuda_parallel, batch_size, opt_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode: ~4.9 iterations/s\n",
    "# GPU RAM before start: 1, 1473\n",
    "# GPU RAM after start: 2656, 4057\n",
    "# GPU util before start: 0%, 5%\n",
    "# GPU util after start: 44%, 40%\n",
    "\n",
    "batch_size = 64\n",
    "opt_level = \"O3\"\n",
    "mixed_precision = True\n",
    "cuda_parallel = True\n",
    "\n",
    "# test_apex_mp_parallel.py used nn.DistributedDataParallel but IT IS NOT COMPLETED (e.g. DistributedSampler(train_dataset))\n",
    "# python -m torch.distributed.launch --nproc_per_node=2 test_apex_mp_parallel.py\n",
    "test_apex(mixed_precision, cuda_parallel, batch_size, opt_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
