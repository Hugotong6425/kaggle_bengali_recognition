{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T06:39:42.326016Z",
     "start_time": "2020-02-11T06:39:42.307360Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T06:40:16.100038Z",
     "start_time": "2020-02-11T06:40:16.076070Z"
    },
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from hw_grapheme.train import generate_stratified_k_fold_index, train_model\n",
    "from hw_grapheme.utils import load_model_weight\n",
    "from hw_grapheme.data_pipeline import create_dataloaders, load_data\n",
    "from hw_grapheme.model.se_resnext50 import se_resnext50 \n",
    "from hw_grapheme.loss_func import Loss_combine\n",
    "\n",
    "# from torchtools.optim import RangerLars, RAdam\n",
    "# from one_cycle import OneCycleLR\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "# from warmup_scheduler import GradualWarmupScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T06:39:52.883104Z",
     "start_time": "2020-02-11T06:39:43.144370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data done, shape: (200840, 224, 224), (200840,), (200840, 3)\n"
     ]
    }
   ],
   "source": [
    "# load data \n",
    "pickle_paths = [\n",
    "    \"../data/processed_data/size_224/train_data_0.pickle\",\n",
    "    \"../data/processed_data/size_224/train_data_1.pickle\",\n",
    "    \"../data/processed_data/size_224/train_data_2.pickle\",\n",
    "    \"../data/processed_data/size_224/train_data_3.pickle\",\n",
    "]\n",
    "\n",
    "image_data, name_data, label_data = load_data(pickle_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T06:39:52.901029Z",
     "start_time": "2020-02-11T06:39:52.885516Z"
    }
   },
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"name\": 'se-resnext50 baseline',\n",
    "    \"model\": \"se-resnext50\",\n",
    "    \"pretrain\": False,\n",
    "    \"head_info\": \"1 fc\",\n",
    "    \"input_size\": \"224X224\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"image_processing\": \"rotate(-10,10), scale(1.0, 1.15)\",\n",
    "    'batch_size': 64,\n",
    "    'num_workers': 8,\n",
    "    'pin_memory': True,\n",
    "    'n_epoch': 48,\n",
    "    'n_splits': 5,\n",
    "    'random_seed': 2020,\n",
    "    'mix_precision': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T06:39:54.343558Z",
     "start_time": "2020-02-11T06:39:52.902957Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "batch_size = configs['batch_size']\n",
    "num_workers = configs['num_workers'] \n",
    "pin_memory = configs['pin_memory']\n",
    "n_epoch = configs['n_epoch']\n",
    "n_splits = configs['n_splits']\n",
    "random_seed = configs['random_seed']\n",
    "mixed_precision = configs['mix_precision']\n",
    "\n",
    "train_idx_list, test_idx_list = generate_stratified_k_fold_index(\n",
    "    image_data, label_data, n_splits, random_seed\n",
    ")\n",
    "\n",
    "# create loss function\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# criterion = Loss_combine()\n",
    "\n",
    "# for discriminative lr\n",
    "# my_list = ['module._fc.weight', 'module._fc.bias']\n",
    "# params = list(filter(lambda kv: kv[0] in my_list, eff_b0.named_parameters()))\n",
    "# base_params = list(filter(lambda kv: kv[0] not in my_list, eff_b0.named_parameters()))\n",
    "# params = [kv[1] for kv in params]\n",
    "# base_params = [kv[1] for kv in base_params]\n",
    "\n",
    "# create data_transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomAffine(degrees=10, scale=(1.0, 1.15)),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.0692], [0.2051]),\n",
    "        # transforms.ToPILImage(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.0692], [0.2051])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T06:39:56.278398Z",
     "start_time": "2020-02-11T06:39:56.248314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20200211_143956'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T06:39:57.132998Z",
     "start_time": "2020-02-11T06:39:57.112937Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import wandb\n",
    "# # os.environ['WANDB_NOTEBOOK_NAME'] = 'model_3_efficient_net'\n",
    "# %env WANDB_NOTEBOOK_NAME=model_3_efficient_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T06:42:47.597402Z",
     "start_time": "2020-02-11T06:40:19.763528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 0\n",
      "Creating train dataloader...\n",
      "Creating test dataloader...\n",
      "Epoch 0/47\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8090b3b03e544f2bb8a9bf6a5f22dc62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2511.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7fde2c2048c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hugo/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/hugo/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/hugo/anaconda3/envs/kaggle/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/hugo/anaconda3/envs/kaggle/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/home/hugo/anaconda3/envs/kaggle/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9f88ee9f514c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mmixed_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mepoch_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     )\n",
      "\u001b[0;32m~/Desktop/kaggle/kaggle_bengali_recognition/hw_grapheme/train.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, dataloaders, mixed_precision, callbacks, num_epochs, epoch_scheduler, batch_scheduler, save_dir)\u001b[0m\n\u001b[1;32m    199\u001b[0m         train_loss, train_root_acc, train_vowel_acc, train_consonant_acc = train_phrase(\n\u001b[1;32m    200\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mnum_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixed_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         )\n\u001b[1;32m    203\u001b[0m         \u001b[0mcombined_train_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_root_acc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_vowel_acc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_consonant_acc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/kaggle/kaggle_bengali_recognition/hw_grapheme/train.py\u001b[0m in \u001b[0;36mtrain_phrase\u001b[0;34m(model, optimizer, train_dataloader, criterion, num_train, mixed_precision, batch_scheduler)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pretrain = configs['pretrain']\n",
    "criterion = Loss_combine()\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(zip(train_idx_list, test_idx_list)):\n",
    "    if i != 0:\n",
    "        continue\n",
    "        \n",
    "    print(f\"Training fold {i}\")\n",
    "    MODEL_DIR = Path(f\"../model_weights/seresnext50_baseline/fold_{i}\")\n",
    "    MODEL_DIR.mkdir(exist_ok=True)\n",
    "    \n",
    "    # create model\n",
    "    model = se_resnext50()\n",
    "\n",
    "    if mixed_precision:\n",
    "        model = apex.parallel.DistributedDataParallel(model)\n",
    "        model.to(\"cuda\")\n",
    "        model = torch.nn.parallel.DistributedDataParallel(\n",
    "            model, device_ids=[0, 1], output_device=0\n",
    "        )\n",
    "        model, optimizer_ft = amp.initialize(\n",
    "            model, optimizer_ft, opt_level=\"O1\"\n",
    "        )\n",
    "    else:\n",
    "        model.to(\"cuda\")\n",
    "        model = nn.DataParallel(model)\n",
    "        # Add W&B logging\n",
    "\n",
    "    # create optimizer\n",
    "    optimizer_ft = optim.Adam(model.parameters(), weight_decay=1e-5)\n",
    "\n",
    "    # create data loader\n",
    "    data_loaders = create_dataloaders(\n",
    "        image_data, name_data, label_data, train_idx, valid_idx,\n",
    "        data_transforms, batch_size, num_workers, pin_memory\n",
    "    )\n",
    "    \n",
    "    callbacks = {}\n",
    "    callbacks = train_model(\n",
    "        model, criterion, optimizer_ft, data_loaders,\n",
    "        mixed_precision, callbacks, num_epochs=n_epoch,\n",
    "        epoch_scheduler=None, save_dir=MODEL_DIR\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-09T17:01:45.834Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "save_root_dir = Path(\"../model_weights/eff_0_baseline\")\n",
    "save_root_dir.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "config_save_path = save_root_dir/\"config.csv\"\n",
    "\n",
    "with open(config_save_path, \"w\") as f:\n",
    "    for key in configs.keys():\n",
    "        f.write(f\"{key},{configs[key]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
